{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd069303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy import optimize\n",
    "from matplotlib import cm\n",
    "from math import isinf\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4fd9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointValuationEnv:\n",
    "    def __init__(self, mean, cov, costs, N, seed=None):\n",
    "        self.mean = np.array(mean)\n",
    "        self.cov = np.array(cov)\n",
    "        self.costs = np.array(costs)\n",
    "        self.N = N\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def sample_valuation(self):\n",
    "        while True:\n",
    "            val = self.rng.multivariate_normal(self.mean, self.cov)\n",
    "            if np.all((val >= 0) & (val <= 1)):\n",
    "                return val\n",
    "\n",
    "    def round(self, offered_products, prices):\n",
    "        valuations = self.sample_valuation()\n",
    "        purchases = np.zeros(self.N, dtype=int)\n",
    "        revenue = 0.0\n",
    "        for i in offered_products:\n",
    "            if valuations[i] >= prices[i]:\n",
    "                purchases[i] = 1\n",
    "                revenue += prices[i] - self.costs[i]\n",
    "        return purchases, revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dbfb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCBPricingAgentWithBudget:\n",
    "    def __init__(self, n_products, n_prices, B, T, reward_range=1, cost_range=1):\n",
    "        self.n_products = n_products\n",
    "        self.n_prices = n_prices\n",
    "        self.K = n_products * n_prices\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        self.budget = B\n",
    "        self.rho = B / T  # budget per round\n",
    "        self.t = 0\n",
    "\n",
    "        self.reward_range = reward_range\n",
    "        self.cost_range = cost_range\n",
    "\n",
    "        self.avg_reward = np.zeros(self.K)\n",
    "        self.avg_cost = np.zeros(self.K)\n",
    "        self.N_pulls = np.zeros(self.K)\n",
    "\n",
    "    def compute_ucbs(self):\n",
    "        # Large value for unexplored arms\n",
    "        large_value = (1 + np.sqrt(2 * np.log(max(self.T,1)) / 1)) * max(self.reward_range, self.cost_range) * 10\n",
    "        \n",
    "        f_ucbs = np.zeros(self.K)\n",
    "        c_lcbs = np.zeros(self.K)\n",
    "        \n",
    "        unexplored = self.N_pulls == 0\n",
    "        f_ucbs[unexplored] = large_value\n",
    "        c_lcbs[unexplored] = 0  # optimistic cost lower bound\n",
    "        \n",
    "        explored = self.N_pulls > 0\n",
    "        f_ucbs[explored] = self.avg_reward[explored] + self.reward_range * np.sqrt(2 * np.log(max(self.T,1)) / self.N_pulls[explored])\n",
    "        c_lcbs[explored] = self.avg_cost[explored] - self.cost_range * np.sqrt(2 * np.log(max(self.T,1)) / self.N_pulls[explored])\n",
    "        c_lcbs = np.clip(c_lcbs, 0, None)  # cost lower bound can't be negative\n",
    "        \n",
    "        return f_ucbs, c_lcbs\n",
    "\n",
    "    def compute_opt(self, f_ucbs, c_lcbs):\n",
    "        # LP: maximize sum(f_ucbs * gamma), s.t. sum(c_lcbs * gamma) <= rho, sum(gamma) = 1, gamma in [0,1]\n",
    "        if np.all(c_lcbs <= 0):\n",
    "            gamma = np.zeros(len(f_ucbs))\n",
    "            gamma[np.argmax(f_ucbs)] = 1.0\n",
    "            return gamma\n",
    "\n",
    "        c = -f_ucbs  # minimize negative reward = maximize reward\n",
    "        A_ub = [c_lcbs]\n",
    "        b_ub = [self.rho]\n",
    "        A_eq = [np.ones(self.K)]\n",
    "        b_eq = [1.0]\n",
    "\n",
    "        res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq,\n",
    "                      bounds=[(0,1)]*self.K, method='highs')\n",
    "\n",
    "        if not res.success:\n",
    "            gamma = np.ones(self.K) / self.K\n",
    "        else:\n",
    "            gamma = np.maximum(0, res.x)\n",
    "            s = gamma.sum()\n",
    "            gamma = gamma / s if s > 0 else np.ones(self.K) / self.K\n",
    "        return gamma\n",
    "\n",
    "    def pull_arm(self):\n",
    "        if self.budget < 1:\n",
    "            return None  # stop pulling\n",
    "        \n",
    "        f_ucbs, c_lcbs = self.compute_ucbs()\n",
    "        gamma = self.compute_opt(f_ucbs, c_lcbs)\n",
    "\n",
    "        # Sample arms from gamma distribution until you get one price for each product\n",
    "        chosen_price_indices = np.full(self.n_products, -1, dtype=int)\n",
    "        chosen_arms = []\n",
    "\n",
    "        # Convert flat indices to (product, price)\n",
    "        # We do repeated sampling with rejection to ensure one price per product\n",
    "        max_trials = 1000\n",
    "        for _ in range(max_trials):\n",
    "            sampled = np.random.choice(self.K, size=self.n_products, p=gamma)\n",
    "            products = sampled // self.n_prices\n",
    "            prices = sampled % self.n_prices\n",
    "            if len(set(products)) == self.n_products:\n",
    "                chosen_price_indices = prices\n",
    "                chosen_arms = list(zip(range(self.n_products), prices))\n",
    "                break\n",
    "        else:\n",
    "            # fallback: choose best price per product greedily\n",
    "            chosen_price_indices = np.argmax(f_ucbs.reshape(self.n_products, self.n_prices), axis=1)\n",
    "            chosen_arms = list(zip(range(self.n_products), chosen_price_indices))\n",
    "\n",
    "        self.last_chosen_arms = chosen_arms\n",
    "        return chosen_arms\n",
    "\n",
    "    def update(self, rewards, costs):\n",
    "        # rewards and costs: arrays of shape (n_products,)\n",
    "        for (prod, price_idx), r, c in zip(self.last_chosen_arms, rewards, costs):\n",
    "            arm_idx = prod * self.n_prices + price_idx\n",
    "            self.N_pulls[arm_idx] += 1\n",
    "            n = self.N_pulls[arm_idx]\n",
    "            self.avg_reward[arm_idx] += (r - self.avg_reward[arm_idx]) / n\n",
    "            self.avg_cost[arm_idx] += (c - self.avg_cost[arm_idx]) / n\n",
    "            self.budget -= c\n",
    "        self.t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "117ad335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clairvoyant_multi(products_prices, win_probabilities, cost=0.0, rho=1.0):\n",
    "    \"\"\"\n",
    "    products_prices: shape (n_products, n_prices) array of prices\n",
    "    win_probabilities: shape (n_products, n_prices) array of win probabilities\n",
    "    cost: scalar cost per product (assumed same across all for simplicity)\n",
    "    rho: budget constraint on total expected \"cost\" (e.g. expected sales)\n",
    "\n",
    "    Returns:\n",
    "        gamma: optimal distribution over all (product, price) pairs, shape (n_products, n_prices)\n",
    "        max_expected_reward: the max expected reward\n",
    "    \"\"\"\n",
    "\n",
    "    n_products, n_prices = products_prices.shape\n",
    "    n_arms = n_products * n_prices\n",
    "\n",
    "    prices_flat = products_prices.flatten()\n",
    "    win_prob_flat = win_probabilities.flatten()\n",
    "\n",
    "    # Objective coefficients (negative for linprog minimization)\n",
    "    c = - (prices_flat - cost) * win_prob_flat\n",
    "\n",
    "    # Constraint 1: sum of expected \"costs\" (win probabilities) * gamma <= rho\n",
    "    A_ub = [win_prob_flat]\n",
    "\n",
    "    b_ub = [rho]\n",
    "\n",
    "    # Constraint 2: For each product, sum of gamma over all prices = 1 (pick exactly one price per product)\n",
    "    A_eq = np.zeros((n_products, n_arms))\n",
    "    for p in range(n_products):\n",
    "        A_eq[p, p*n_prices:(p+1)*n_prices] = 1\n",
    "    b_eq = np.ones(n_products)\n",
    "\n",
    "    bounds = [(0, 1) for _ in range(n_arms)]\n",
    "\n",
    "    res = optimize.linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')\n",
    "\n",
    "    if not res.success:\n",
    "        raise RuntimeError(\"Linear program did not converge\")\n",
    "\n",
    "    gamma = res.x.reshape((n_products, n_prices))\n",
    "    max_expected_reward = -res.fun\n",
    "\n",
    "    return gamma, max_expected_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9df0c89",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     29\u001b[39m     win_probabilities[p] = \u001b[32m1\u001b[39m - valuation.cdf(prices)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Compute clairvoyant LP solution and expected utility per round\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# You will need to define compute_clairvoyant_multi to handle multiple products and prices\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m gamma_opt, expected_clairvoyant_utility = \u001b[43mcompute_clairvoyant_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_probabilities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Initialize environment & agent\u001b[39;00m\n\u001b[32m     36\u001b[39m env = JointValuationEnv(means, np.diag(scales**\u001b[32m2\u001b[39m), cost=np.zeros(n_products), N=n_products, seed=epoch)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mcompute_clairvoyant_multi\u001b[39m\u001b[34m(products_prices, win_probabilities, cost, rho)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_clairvoyant_multi\u001b[39m(products_prices, win_probabilities, cost=\u001b[32m0.0\u001b[39m, rho=\u001b[32m1.0\u001b[39m):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    products_prices: shape (n_products, n_prices) array of prices\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    win_probabilities: shape (n_products, n_prices) array of win probabilities\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[33;03m        max_expected_reward: the max expected reward\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     n_products, n_prices = products_prices.shape\n\u001b[32m     14\u001b[39m     n_arms = n_products * n_prices\n\u001b[32m     16\u001b[39m     prices_flat = products_prices.flatten()\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "# Assuming your JointValuationEnv and UCBPricingAgentWithBudget classes are defined\n",
    "\n",
    "# Environment params\n",
    "n_products = 3\n",
    "T = 12000\n",
    "B = 6500\n",
    "rho = B / T\n",
    "epsilon = T ** (-0.33)\n",
    "K = int(1 / epsilon)\n",
    "prices = np.linspace(0, 1, K)\n",
    "n_epochs = 1\n",
    "\n",
    "# Define means and stddevs for each product's valuation distribution\n",
    "means = np.array([0.4, 0.5, 0.6])\n",
    "scales = np.array([0.1, 0.1, 0.1])\n",
    "\n",
    "all_regrets = []\n",
    "all_rewards = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Compute win probabilities (1 - CDF) per product and price\n",
    "    win_probabilities = np.zeros((n_products, K))\n",
    "    for p in range(n_products):\n",
    "        valuation = stats.norm(loc=means[p], scale=scales[p])\n",
    "        win_probabilities[p] = 1 - valuation.cdf(prices)\n",
    "\n",
    "    # Compute clairvoyant LP solution and expected utility per round\n",
    "    # You will need to define compute_clairvoyant_multi to handle multiple products and prices\n",
    "    gamma_opt, expected_clairvoyant_utility = compute_clairvoyant_multi(prices, rho, win_probabilities)\n",
    "\n",
    "    # Initialize environment & agent\n",
    "    env = JointValuationEnv(means, np.diag(scales**2), cost=np.zeros(n_products), N=n_products, seed=epoch)\n",
    "    agent = UCBPricingAgentWithBudget(n_products, K, B, T, reward_range=1, cost_range=1)\n",
    "\n",
    "    rewards_history = []\n",
    "    regrets = []\n",
    "\n",
    "    for t in range(T):\n",
    "        chosen_arms = agent.pull_arm()\n",
    "        if chosen_arms is None:\n",
    "            # Budget exhausted\n",
    "            rewards_history.append(0)\n",
    "            regrets.append(expected_clairvoyant_utility)\n",
    "            continue\n",
    "\n",
    "        # Prepare prices vector for environment call\n",
    "        chosen_products = [prod for prod, price_idx in chosen_arms]\n",
    "        chosen_price_indices = [price_idx for prod, price_idx in chosen_arms]\n",
    "        offered_prices = np.zeros(n_products)\n",
    "        offered_prices[chosen_products] = prices[chosen_price_indices]\n",
    "\n",
    "        # Get purchases and revenue from env\n",
    "        purchases, revenue = env.round(chosen_products, offered_prices)\n",
    "\n",
    "        # Prepare reward and cost arrays for update (cost=0)\n",
    "        rewards_arr = np.zeros(n_products)\n",
    "        costs_arr = np.zeros(n_products)\n",
    "\n",
    "        for prod, price_idx in chosen_arms:\n",
    "            rewards_arr[prod] = prices[price_idx] if purchases[prod] == 1 else 0\n",
    "            costs_arr[prod] = 0  # costs ignored per your request\n",
    "\n",
    "        agent.update(rewards_arr, costs_arr)\n",
    "\n",
    "        rewards_history.append(revenue)\n",
    "        regrets.append(expected_clairvoyant_utility - revenue)\n",
    "\n",
    "    all_regrets.append(np.cumsum(regrets))\n",
    "    all_rewards.append(np.cumsum(rewards_history))\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} done: Total reward = {sum(rewards_history):.2f}\")\n",
    "\n",
    "# Compute average regret and rewards across epochs\n",
    "avg_regret = np.mean(all_regrets, axis=0)\n",
    "avg_rewards = np.mean(all_rewards, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(10, 15), constrained_layout=True)\n",
    "\n",
    "# 1) Chosen Prices per Product (pull counts)\n",
    "for p in range(n_products):\n",
    "    axs[0].plot(prices, avg_pulls[p], label=f'Product {p+1}')\n",
    "    axs[0].fill_between(prices, avg_pulls[p] - std_pulls[p], avg_pulls[p] + std_pulls[p], alpha=0.3)\n",
    "axs[0].set_xlabel('Price')\n",
    "axs[0].set_ylabel('Number of pulls')\n",
    "axs[0].set_title('Chosen Prices per Product')\n",
    "axs[0].legend()\n",
    "\n",
    "# 2) Cumulative Payments\n",
    "axs[1].plot(np.arange(T), avg_payments, label='Average Payments')\n",
    "axs[1].fill_between(np.arange(T), avg_payments - std_payments, avg_payments + std_payments, alpha=0.3)\n",
    "axs[1].axhline(B, color='red', linestyle='--', label='Budget')\n",
    "axs[1].set_xlabel('Round $t$')\n",
    "axs[1].set_ylabel('Cumulative Payments')\n",
    "axs[1].set_title('Cumulative Payments of UCBPricingAgentWithBudget')\n",
    "axs[1].legend()\n",
    "\n",
    "# 3) Cumulative Regret\n",
    "axs[2].plot(np.arange(T), avg_regret, label='Average Regret')\n",
    "axs[2].fill_between(np.arange(T), avg_regret - std_regret, avg_regret + std_regret, alpha=0.3)\n",
    "axs[2].set_xlabel('Round $t$')\n",
    "axs[2].set_ylabel('Cumulative Regret')\n",
    "axs[2].set_title('Cumulative Regret of UCBPricingAgentWithBudget')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
